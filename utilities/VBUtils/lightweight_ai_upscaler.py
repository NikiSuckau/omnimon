#!/usr/bin/env python3
"""
Lightweight AI Background Upscaler
Uses simple but effective AI techniques for background generation.
"""

import cv2
import numpy as np
from pathlib import Path
from PIL import Image, ImageFilter, ImageEnhance
import argparse

def create_intelligent_edge_extension(image, mask):
    """Create intelligent edge extension using content-aware techniques."""
    print("üß† Applying intelligent edge extension...")
    
    height, width = image.shape[:2]
    result = image.copy()
    
    # Analyze the original content to understand the background pattern
    # Get the central content area (original 80x160)
    center_start = 40
    center_end = 120
    center_content = image[:, center_start:center_end]
    
    # Analyze edge patterns for better extension
    left_edge = center_content[:, :20]  # Left 20 pixels of original
    right_edge = center_content[:, -20:]  # Right 20 pixels of original
    
    print("  üé® Analyzing color gradients and patterns...")
    
    # Create gradients for seamless blending
    for x in range(40):  # Fill left 40 pixels
        # Calculate blend ratio (stronger near center)
        blend_ratio = (40 - x) / 40.0
        
        # Sample from left edge with some variation
        source_x = min(x % 20, 19)
        
        for y in range(height):
            # Get the source pixel from left edge
            source_pixel = left_edge[y, source_x]
            
            # Add some natural variation
            variation = np.random.normal(0, 5, 3)
            varied_pixel = np.clip(source_pixel.astype(float) + variation, 0, 255)
            
            # Create smooth gradient from edge to outside
            if x < 10:  # Outer region - more variation
                fade_factor = 0.8 + 0.2 * np.random.random()
                result[y, x] = (varied_pixel * fade_factor).astype(np.uint8)
            else:  # Inner region - blend with original
                original_pixel = result[y, x]
                blended = blend_ratio * varied_pixel + (1 - blend_ratio) * original_pixel
                result[y, x] = blended.astype(np.uint8)
    
    # Similar process for right side
    for x in range(120, 160):  # Fill right 40 pixels
        offset = x - 120
        blend_ratio = offset / 40.0
        
        # Sample from right edge
        source_x = min(offset % 20, 19)
        
        for y in range(height):
            source_pixel = right_edge[y, -(source_x + 1)]
            
            # Add variation
            variation = np.random.normal(0, 5, 3)
            varied_pixel = np.clip(source_pixel.astype(float) + variation, 0, 255)
            
            if offset > 30:  # Outer region
                fade_factor = 0.8 + 0.2 * np.random.random()
                result[y, x] = (varied_pixel * fade_factor).astype(np.uint8)
            else:  # Inner region
                original_pixel = result[y, x]
                blended = (1 - blend_ratio) * varied_pixel + blend_ratio * original_pixel
                result[y, x] = blended.astype(np.uint8)
    
    return result

def apply_color_harmonization(image):
    """Apply color harmonization to make the result look more natural."""
    print("  üé® Applying color harmonization...")
    
    # Convert to PIL for advanced processing
    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    
    # Slightly enhance saturation in the extended areas
    enhancer = ImageEnhance.Color(pil_image)
    enhanced = enhancer.enhance(1.1)
    
    # Apply subtle gaussian blur to smooth transitions
    smooth = enhanced.filter(ImageFilter.GaussianBlur(radius=0.5))
    
    # Blend original with smoothed version
    final = Image.blend(enhanced, smooth, 0.3)
    
    # Convert back to OpenCV
    return cv2.cvtColor(np.array(final), cv2.COLOR_RGB2BGR)

def create_depth_aware_extension(image, mask):
    """Create depth-aware extension based on perspective analysis."""
    print("üèûÔ∏è  Creating depth-aware extension...")
    
    height, width = image.shape[:2]
    result = image.copy()
    
    # Analyze vertical gradients to understand perspective
    center_content = image[:, 40:120]
    
    # Calculate average color per row to understand depth changes
    row_averages = []
    for y in range(height):
        row_avg = np.mean(center_content[y, :], axis=0)
        row_averages.append(row_avg)
    
    # Extend based on depth understanding
    for x in range(40):  # Left extension
        depth_factor = (40 - x) / 40.0  # How far from center
        
        for y in range(height):
            # Base color from row average
            base_color = row_averages[y]
            
            # Add perspective-aware variation
            # Colors should get slightly more muted with distance
            depth_variation = base_color * (0.9 + 0.1 * (1 - depth_factor))
            
            # Add some texture variation
            texture_noise = np.random.normal(0, 3, 3)
            final_color = np.clip(depth_variation + texture_noise, 0, 255)
            
            result[y, x] = final_color.astype(np.uint8)
    
    # Right extension
    for x in range(120, 160):
        depth_factor = (x - 120) / 40.0
        
        for y in range(height):
            base_color = row_averages[y]
            depth_variation = base_color * (0.9 + 0.1 * (1 - depth_factor))
            texture_noise = np.random.normal(0, 3, 3)
            final_color = np.clip(depth_variation + texture_noise, 0, 255)
            
            result[y, x] = final_color.astype(np.uint8)
    
    return result

def lightweight_ai_upscale(input_path, output_dir):
    """Upscale using lightweight AI techniques."""
    print(f"\nüñºÔ∏è  Processing with lightweight AI: {input_path.name}")
    
    # Load image
    original = cv2.imread(str(input_path))
    if original is None:
        print(f"‚ùå Could not load {input_path}")
        return False
    
    height, width = original.shape[:2]
    print(f"üìê Original: {width}x{height}")
    
    # Create canvas and place original
    canvas = np.zeros((160, 160, 3), dtype=np.uint8)
    x_offset = (160 - width) // 2
    y_offset = (160 - height) // 2
    canvas[y_offset:y_offset+height, x_offset:x_offset+width] = original
    
    # Create mask
    mask = np.zeros((160, 160), dtype=np.uint8)
    mask[:, :x_offset] = 255
    mask[:, x_offset + width:] = 255
    
    # Apply different techniques and blend
    print("ü§ñ Applying lightweight AI techniques...")
    
    # Technique 1: Intelligent edge extension
    result1 = create_intelligent_edge_extension(canvas, mask)
    
    # Technique 2: Depth-aware extension
    result2 = create_depth_aware_extension(canvas, mask)
    
    # Technique 3: Traditional inpainting for comparison
    result3 = cv2.inpaint(canvas, mask, 8, cv2.INPAINT_TELEA)
    
    # Blend results intelligently
    print("  üé≠ Blending multiple AI techniques...")
    final_result = (
        0.5 * result1.astype(np.float32) +
        0.3 * result2.astype(np.float32) +
        0.2 * result3.astype(np.float32)
    ).astype(np.uint8)
    
    # Apply final color harmonization
    final_result = apply_color_harmonization(final_result)
    
    # Save result
    output_path = output_dir / f"lightweight_ai_{input_path.name}"
    cv2.imwrite(str(output_path), final_result)
    
    print(f"‚úÖ Lightweight AI result saved: {output_path.name}")
    return True

def process_all_lightweight(input_dir, output_dir):
    """Process all backgrounds with lightweight AI."""
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    output_path.mkdir(exist_ok=True)
    
    png_files = list(input_path.glob("bg_*.png"))
    if not png_files:
        print("‚ùå No background images found!")
        return
    
    print(f"üìä Processing {len(png_files)} images with lightweight AI...")
    
    success_count = 0
    for i, png_file in enumerate(png_files, 1):
        print(f"\nüìã Processing {i}/{len(png_files)}")
        if lightweight_ai_upscale(png_file, output_path):
            success_count += 1
    
    print(f"\nüéâ Lightweight AI processing complete!")
    print(f"   ‚úÖ Successfully processed: {success_count}/{len(png_files)} images")
    print(f"   üìÅ Output directory: {output_path.absolute()}")

def main():
    """Main function."""
    parser = argparse.ArgumentParser(description='Lightweight AI background upscaler')
    parser.add_argument('--input', '-i', default='backgrounds',
                       help='Input directory with background images')
    parser.add_argument('--output', '-o', default='backgrounds_lightweight_ai',
                       help='Output directory for upscaled images')
    
    args = parser.parse_args()
    
    print("ü§ñ Lightweight AI Background Upscaler")
    print("=" * 50)
    
    process_all_lightweight(args.input, args.output)

if __name__ == "__main__":
    main()