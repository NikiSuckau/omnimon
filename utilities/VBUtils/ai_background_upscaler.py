#!/usr/bin/env python3
"""
Generative AI Background Upscaler for VB Utils
Uses local AI models for true content generation and inpainting.
"""

import os
import cv2
import numpy as np
from pathlib import Path
from PIL import Image
import argparse

def check_and_install_ai_dependencies():
    """Check and install required AI packages."""
    print("üîç Checking AI dependencies...")
    
    packages_needed = []
    
    try:
        import torch
        print("‚úÖ PyTorch available")
    except ImportError:
        packages_needed.append("torch torchvision")
        print("‚ùå PyTorch not found")
    
    try:
        import diffusers
        print("‚úÖ Diffusers available")
    except ImportError:
        packages_needed.append("diffusers")
        print("‚ùå Diffusers not found")
    
    try:
        import transformers
        print("‚úÖ Transformers available")
    except ImportError:
        packages_needed.append("transformers")
        print("‚ùå Transformers not found")
    
    try:
        import accelerate
        print("‚úÖ Accelerate available")
    except ImportError:
        packages_needed.append("accelerate")
        print("‚ùå Accelerate not found")
    
    if packages_needed:
        print(f"\nüì¶ Installing required packages: {' '.join(packages_needed)}")
        print("‚ö†Ô∏è  This may take several minutes and require ~4GB of disk space...")
        
        install_cmd = f"pip install {' '.join(packages_needed)}"
        print(f"Run: {install_cmd}")
        return False
    
    return True

def setup_stable_diffusion_inpainting():
    """Set up Stable Diffusion inpainting pipeline."""
    print("ü§ñ Setting up Stable Diffusion inpainting pipeline...")
    
    try:
        from diffusers import StableDiffusionInpaintPipeline
        import torch
        
        # Use a smaller, faster model that works well for inpainting
        model_id = "runwayml/stable-diffusion-inpainting"
        
        # Check if CUDA is available
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"üñ•Ô∏è  Using device: {device}")
        
        if device == "cpu":
            print("‚ö†Ô∏è  Using CPU - this will be slower but should work")
            # Use float32 for CPU
            pipe = StableDiffusionInpaintPipeline.from_pretrained(
                model_id,
                torch_dtype=torch.float32,
                use_safetensors=True
            )
        else:
            print("üöÄ Using GPU acceleration")
            pipe = StableDiffusionInpaintPipeline.from_pretrained(
                model_id,
                torch_dtype=torch.float16,
                use_safetensors=True
            )
        
        pipe = pipe.to(device)
        
        # Optimize for memory usage
        if hasattr(pipe, 'enable_attention_slicing'):
            pipe.enable_attention_slicing()
        if hasattr(pipe, 'enable_model_cpu_offload') and device == "cuda":
            pipe.enable_model_cpu_offload()
        
        print("‚úÖ Stable Diffusion pipeline ready!")
        return pipe
        
    except Exception as e:
        print(f"‚ùå Error setting up Stable Diffusion: {e}")
        return None

def setup_lama_inpainting():
    """Set up LaMa (Large Mask Inpainting) as fallback."""
    print("ü¶ô Setting up LaMa inpainting as fallback...")
    
    try:
        # Try to use a simpler inpainting model
        from diffusers import DDPMScheduler
        import torch
        
        # For now, return None and we'll implement a simpler approach
        print("‚ö†Ô∏è  LaMa not available, using enhanced OpenCV approach")
        return None
        
    except Exception as e:
        print(f"‚ùå LaMa setup failed: {e}")
        return None

def create_intelligent_prompt(image_analysis):
    """Create an intelligent prompt based on image analysis."""
    
    # Analyze the image content to generate appropriate prompts
    prompts = [
        "detailed fantasy landscape, mystical atmosphere, seamless continuation",
        "cinematic background, dramatic lighting, atmospheric perspective", 
        "anime style background, detailed environment, consistent art style",
        "game background art, pixel perfect details, seamless tiling",
        "digital painting, concept art style, environmental details"
    ]
    
    # For now, use a general purpose prompt
    # In the future, we could analyze the image content to pick better prompts
    return "seamless background extension, consistent art style, detailed environment, perfect blend"

def ai_inpaint_background(image, mask, pipe=None):
    """Use AI to intelligently fill missing background areas."""
    print("üé® Applying AI-powered content generation...")
    
    if pipe is None:
        print("‚ö†Ô∏è  No AI pipeline available, using enhanced fallback...")
        return enhanced_opencv_inpainting(image, mask)
    
    try:
        # Convert OpenCV image to PIL
        if len(image.shape) == 3:
            pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        else:
            pil_image = Image.fromarray(image)
        
        # Convert mask to PIL
        pil_mask = Image.fromarray(mask)
        
        # Ensure both images are the right size
        target_size = (512, 512)  # Stable Diffusion works best at 512x512
        
        # Resize for processing
        original_size = pil_image.size
        pil_image_resized = pil_image.resize(target_size, Image.LANCZOS)
        pil_mask_resized = pil_mask.resize(target_size, Image.NEAREST)
        
        # Create prompt based on image analysis
        prompt = create_intelligent_prompt(None)
        
        print(f"  üéØ Using prompt: '{prompt}'")
        print(f"  üìê Processing at {target_size}, will resize back to {original_size}")
        
        # Generate inpainted result
        result = pipe(
            prompt=prompt,
            image=pil_image_resized,
            mask_image=pil_mask_resized,
            num_inference_steps=20,  # Fewer steps for speed
            guidance_scale=7.5,
            strength=0.8
        ).images[0]
        
        # Resize back to original size
        result_resized = result.resize(original_size, Image.LANCZOS)
        
        # Convert back to OpenCV format
        result_cv = cv2.cvtColor(np.array(result_resized), cv2.COLOR_RGB2BGR)
        
        print("‚úÖ AI inpainting completed!")
        return result_cv
        
    except Exception as e:
        print(f"‚ùå AI inpainting failed: {e}")
        print("üîÑ Falling back to enhanced OpenCV method...")
        return enhanced_opencv_inpainting(image, mask)

def enhanced_opencv_inpainting(image, mask):
    """Enhanced OpenCV inpainting with multiple techniques."""
    print("üîß Applying enhanced OpenCV inpainting...")
    
    # Multi-pass inpainting with different techniques
    results = []
    
    # Pass 1: Telea algorithm (good for textures)
    result1 = cv2.inpaint(image, mask, 10, cv2.INPAINT_TELEA)
    results.append(result1)
    
    # Pass 2: Navier-Stokes (good for smooth areas)
    result2 = cv2.inpaint(image, mask, 10, cv2.INPAINT_NS)
    results.append(result2)
    
    # Pass 3: Multi-scale approach
    # Downscale, inpaint, upscale for better structure
    small_img = cv2.resize(image, (image.shape[1]//2, image.shape[0]//2))
    small_mask = cv2.resize(mask, (mask.shape[1]//2, mask.shape[0]//2))
    small_result = cv2.inpaint(small_img, small_mask, 5, cv2.INPAINT_TELEA)
    result3 = cv2.resize(small_result, (image.shape[1], image.shape[0]))
    results.append(result3)
    
    # Intelligent blending based on local image properties
    final_result = np.zeros_like(image, dtype=np.float32)
    
    for i, result in enumerate(results):
        weight = [0.4, 0.4, 0.2][i]  # Weights for each method
        final_result += result.astype(np.float32) * weight
    
    return final_result.astype(np.uint8)

def upscale_background_with_ai(input_path, output_dir, ai_pipe=None):
    """Upscale background using AI generation."""
    print(f"\nüñºÔ∏è  Processing with AI: {input_path.name}")
    
    # Load original image
    original = cv2.imread(str(input_path))
    if original is None:
        print(f"‚ùå Could not load {input_path}")
        return False
    
    height, width = original.shape[:2]
    print(f"üìê Original size: {width}x{height}")
    
    # Create 160x160 canvas
    canvas = np.zeros((160, 160, 3), dtype=np.uint8)
    
    # Center the original image
    x_offset = (160 - width) // 2
    y_offset = (160 - height) // 2
    canvas[y_offset:y_offset+height, x_offset:x_offset+width] = original
    
    # Create mask for areas to fill
    mask = np.zeros((160, 160), dtype=np.uint8)
    mask[:, :x_offset] = 255  # Left side
    mask[:, x_offset + width:] = 255  # Right side
    
    print(f"üé≠ Mask created: filling {x_offset} pixels on each side")
    
    # Apply AI inpainting
    result = ai_inpaint_background(canvas, mask, ai_pipe)
    
    # Save result
    output_path = output_dir / f"ai_upscaled_{input_path.name}"
    cv2.imwrite(str(output_path), result)
    
    print(f"‚úÖ AI upscaled image saved: {output_path.name}")
    return True

def process_all_with_ai(input_dir, output_dir):
    """Process all backgrounds with AI upscaling."""
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    # Create output directory
    output_path.mkdir(exist_ok=True)
    
    # Find background files
    png_files = list(input_path.glob("bg_*.png"))
    
    if not png_files:
        print("‚ùå No background images found!")
        return
    
    print(f"üìä Found {len(png_files)} images to process with AI")
    
    # Set up AI pipeline
    print("\nü§ñ Initializing AI pipeline...")
    ai_pipe = setup_stable_diffusion_inpainting()
    
    if ai_pipe is None:
        print("‚ö†Ô∏è  AI pipeline not available, using enhanced OpenCV fallback")
    
    # Process each image
    success_count = 0
    for i, png_file in enumerate(png_files, 1):
        print(f"\nüìã Processing {i}/{len(png_files)}")
        if upscale_background_with_ai(png_file, output_path, ai_pipe):
            success_count += 1
    
    print(f"\nüéâ AI Processing complete!")
    print(f"   ‚úÖ Successfully processed: {success_count}/{len(png_files)} images")
    print(f"   üìÅ Output directory: {output_path.absolute()}")

def main():
    """Main function."""
    parser = argparse.ArgumentParser(description='AI-powered background upscaler')
    parser.add_argument('--input', '-i', default='backgrounds',
                       help='Input directory with background images')
    parser.add_argument('--output', '-o', default='backgrounds_ai_upscaled',
                       help='Output directory for AI upscaled images')
    parser.add_argument('--check-deps', action='store_true',
                       help='Check and install AI dependencies')
    
    args = parser.parse_args()
    
    print("ü§ñ AI-Powered Background Upscaler")
    print("=" * 50)
    
    if args.check_deps:
        check_and_install_ai_dependencies()
        return
    
    # Check dependencies
    if not check_and_install_ai_dependencies():
        print("\n‚ùå AI dependencies not available!")
        print("Run with --check-deps to install required packages")
        print("Or install manually:")
        print("  pip install torch torchvision diffusers transformers accelerate")
        return
    
    # Process backgrounds
    process_all_with_ai(args.input, args.output)

if __name__ == "__main__":
    main()